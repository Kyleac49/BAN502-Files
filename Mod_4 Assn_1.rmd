---
output:
  word_document: default
  html_document: default
---
# BAN 502

## Kyle Capponcelli

### Mod 4 Assignment 1


Library Load
```{r}
options(tidyverse.quiet = TRUE)
library("tidyverse")
library("mice")
library("VIM")

```

Data Load
```{r}
class_grades <- read_csv("class-grades.csv")
View(class_grades)
```


#### Task 1

```{r}
summary(class_grades)
str(class_grades)
```
There are 11 pieces of missing data (NAs) in the "class_grades" data-set. 1 is in "Tutorial", 3 are in "Midterm", 3 are in "TakeHome" and 4 are in "Final".

#### Task 2

View Missingness
```{r}
vim_plot = aggr(class_grades, numbers = TRUE, prop = c(TRUE, FALSE), cex.axis=.7)
```

There does not appear to be any consistent missingness in the data set, of the 11 pieces of missing data only one student appears to be missing 2 items (Midterm and TakeHome) and all other students with missing data appear to be only missing one piece of data.

#### Task 3

Row-wise Deletion of missing data
```{r}
class_row = class_grades %>% drop_na(Tutorial, Midterm, TakeHome, Final)
str(class_row)
```

89 rows remain in this new data frame after deleting rows in "class_grades"

#### Task 4

Column-wise Deletion
```{r}
class_column = class_grades %>% select(-Tutorial, -Midterm, -TakeHome, -Final)
str(class_column)
```

99 rows remain in this new data frame after deleting columns in "class_grades".

#### Task 5
Row-wise deletion (task 3) seems preferable in this data set as we still keep the majority of the data from class_grades which will allow us to continue our analysis. Column-wise deletion removes too much good data and would cripple any model we would try to build to predict student performance as we would only have 2 columns of data left to attempt to make any predictions (all of which now contain no missing data).

#### Task 6
```{r}
grades_imp = mice(class_grades, m=1, method = "pmm", seed = 12345)
#in line above: m=1 -> runs one imputation, seed sets the random number seed to get repeatable results
summary(grades_imp)
densityplot(grades_imp)
#red imputed, blue original, only shows density plots when more than 1 value the variable was imputed
#note that the density plots are fairly uninteresting given the small amount of missing data
grades_complete = complete(grades_imp)
summary(grades_complete)
```

#### Task 7
One of the major issues that can arrise from imputing data into missing data variables is that if a column has too many pieces of missing information and you use a predictive mean to impute data, then you could essentially make that column useless. If the mean of the data that is available is not drastically spread out then you are allowing for a narrow set range of imputed information to be created that may create the issue of making that column not have a value of significance when it may have been significant as a predictor. The other issue is that the imputed data may not match well with the data currently present and this will scew future predictions. Looking at the result of the imputed data in task 6 I might question the data that was imputed for Midterm as it appears to fall relatively far from the scale of the original data. I might consider another means of imputing the data.
